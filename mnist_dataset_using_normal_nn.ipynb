{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist dataset using normal nn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gauravbansal98/mnist_dataset_using_normal_nn_1_06_2018/blob/master/mnist_dataset_using_normal_nn.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "X9OzX8amdduC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L_UtNyfcdnbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2VTGOTTdtNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jk1UZShwdwUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"drive/mnist dataset using normal nn\", one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JvhtZaxJdyOm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/mixuala/colab_utils\n",
        "import colab_utils.tboard\n",
        "ROOT = %pwd\n",
        "print(ROOT)\n",
        "LOG_DIR = os.path.join(ROOT, 'gaurav')\n",
        "print(LOG_DIR)\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=LOG_DIR )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Awnt015eQHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "no_of_layers = tf.constant(3, name = \"no_of_layers\")\n",
        "no_of_nodes_l1 = tf.constant(500, name = \"no_of_nodes_l1\")\n",
        "no_of_nodes_l2 = tf.constant(500, name = \"no_of_nodes_l2\")\n",
        "no_of_nodes_in_output_layer = tf.constant(10, name = \"no_of_nodes_in_output_layer\")\n",
        "batch_size = 128\n",
        "hm_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTG4vG1Recc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(dtype = tf.float32, shape = [None, None], name = \"input_labels\")\n",
        "y = tf.placeholder(dtype = tf.float32, shape = [None, None], name = \"output_labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H1ML__G9eeVI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def neural_network_model(data):\n",
        "  \n",
        "  with tf.name_scope('neural_network'):\n",
        "  \n",
        "    hidden_layer1 = {\"weights_l1\" : tf.Variable(tf.random_normal([784, no_of_nodes_l1])),\n",
        "                     \"biases_l1\" : tf.Variable(tf.random_normal([1, no_of_nodes_l1]))}\n",
        "    hidden_layer2 = {\"weights_l2\" : tf.Variable(tf.random_normal([no_of_nodes_l1, no_of_nodes_l2])),\n",
        "                     \"biases_l2\" : tf.Variable(tf.random_normal([1, no_of_nodes_l2]))}\n",
        "    output_layer = {\"weights_ol\": tf.Variable(tf.random_normal([no_of_nodes_l2, no_of_nodes_in_output_layer])), \n",
        "                   \"biases_ol\": tf.Variable(tf.random_normal([1, no_of_nodes_in_output_layer]))}\n",
        "\n",
        "    z1 = tf.add(tf.matmul(data, hidden_layer1[\"weights_l1\"]), hidden_layer1[\"biases_l1\"])\n",
        "    a1 = tf.nn.relu(z1)\n",
        "    z2 = tf.add(tf.matmul(a1, hidden_layer2[\"weights_l2\"]), hidden_layer2[\"biases_l2\"])\n",
        "    a2 = tf.nn.relu(z2)\n",
        "  \n",
        "    output = tf.add(tf.matmul(a2, output_layer[\"weights_ol\"]), output_layer[\"biases_ol\"])\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrHadftlegCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network(x):\n",
        "\n",
        "  prediction = neural_network_model(x)\n",
        "  \n",
        "  with tf.name_scope('cost'):\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
        "  summary = tf.summary.scalar('total_cost_of_batch', cost)\n",
        "  \n",
        "  with tf.name_scope('optimizer'):\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  merged = tf.summary.merge_all()\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    train_writer = tf.summary.FileWriter('./gaurav',sess.graph)\n",
        "    k = 0\n",
        "    for i in range(hm_epochs):\n",
        "      epoch_loss = 0\n",
        "      for j in range(int(mnist.train.num_examples/batch_size)):\n",
        "        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "        o, c, m = sess.run([optimizer, cost, merged], feed_dict = {x : epoch_x, y : epoch_y})\n",
        "        epoch_loss += c\n",
        "        train_writer.add_summary(m, k)\n",
        "        k += 1\n",
        "      print('epoch' , i, 'completed out of ', hm_epochs, 'loss ', epoch_loss)\n",
        "      \n",
        "      \n",
        "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "  \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "  \n",
        "    print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels})) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xH5M7H9KemBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8bc81fe8-c6fe-4d7c-de99-15681a688294"
      },
      "cell_type": "code",
      "source": [
        "train_neural_network(x)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 completed out of  10 loss  113543.1298904419\n",
            "epoch 1 completed out of  10 loss  29520.10003376007\n",
            "epoch 2 completed out of  10 loss  17828.107043981552\n",
            "epoch 3 completed out of  10 loss  11445.93170452118\n",
            "epoch 4 completed out of  10 loss  7563.912250354886\n",
            "epoch 5 completed out of  10 loss  5491.495393703692\n",
            "epoch 6 completed out of  10 loss  3786.446009475723\n",
            "epoch 7 completed out of  10 loss  2804.525605773786\n",
            "epoch 8 completed out of  10 loss  2097.379685644888\n",
            "epoch 9 completed out of  10 loss  1350.1484947205056\n",
            "Accuracy: 0.9503\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}